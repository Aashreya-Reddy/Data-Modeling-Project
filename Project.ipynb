{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Model - Simple SVM\n",
    "#Best cross-validation score: 0.906\n",
    "#Best Parameters {'C': 0.001, 'multi_class': 'crammer_singer', 'penalty': 'l1'}\n",
    "#train score:  0.904\n",
    "#test score:  1.0\n",
    "\n",
    "#Three things i've tried that were not covered in class are- \n",
    "#-->Randomized search CV with MLPClassifier model\n",
    "#-->Saving and Uploading models using pickle\n",
    "#-->GaussianProcessClassifier\n",
    "\n",
    "#Comments\n",
    "#--worked a lot on hyperparmeter tuning and selected the most appropriate so that when i run it again, it won't take long\n",
    "#Referred https://scikit-learn.org/ for hyperparameters  \n",
    "#--used randomsampling of the train dataset to run models faster\n",
    "#--I've split the train dataset into train and test so that i can verify how my models work \n",
    "#  before predicting the test dataset provided and uploading on kaggle.\n",
    "#--Made sure to resolve all the warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading test dataset into \"test\"\n",
    "import pandas as pd\n",
    "\n",
    "test= pd.read_csv(r'/Users/Desktop/MLPROJECT2/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Sampling of train data and loading into \"data\"\n",
    "import random\n",
    "\n",
    "f = \"/Users/Desktop/MLPROJECT2/train.csv\"\n",
    "num_lines = sum(1 for l in open(f))\n",
    "size = int(num_lines /10)\n",
    "skip_idx = random.sample(range(1, num_lines), num_lines - size)\n",
    "data = pd.read_csv(f, skiprows=skip_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245376</td>\n",
       "      <td>1.812653</td>\n",
       "      <td>-0.476162</td>\n",
       "      <td>-0.338988</td>\n",
       "      <td>1.386750</td>\n",
       "      <td>-0.745965</td>\n",
       "      <td>-0.449870</td>\n",
       "      <td>-0.492226</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>1.129394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252668</td>\n",
       "      <td>0.655719</td>\n",
       "      <td>0.090057</td>\n",
       "      <td>-0.136884</td>\n",
       "      <td>-0.172452</td>\n",
       "      <td>-0.556921</td>\n",
       "      <td>0.036490</td>\n",
       "      <td>-0.021575</td>\n",
       "      <td>79.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202483</td>\n",
       "      <td>-1.014219</td>\n",
       "      <td>0.522775</td>\n",
       "      <td>-0.337978</td>\n",
       "      <td>-1.957797</td>\n",
       "      <td>3.578395</td>\n",
       "      <td>3.266965</td>\n",
       "      <td>0.602857</td>\n",
       "      <td>0.644645</td>\n",
       "      <td>-0.305879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147742</td>\n",
       "      <td>0.590740</td>\n",
       "      <td>-0.680551</td>\n",
       "      <td>0.745346</td>\n",
       "      <td>1.119496</td>\n",
       "      <td>0.013520</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>-0.132643</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221275</td>\n",
       "      <td>-0.600317</td>\n",
       "      <td>0.915481</td>\n",
       "      <td>0.835746</td>\n",
       "      <td>-0.621856</td>\n",
       "      <td>1.284060</td>\n",
       "      <td>-0.070605</td>\n",
       "      <td>1.042698</td>\n",
       "      <td>-0.072551</td>\n",
       "      <td>-0.394966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275582</td>\n",
       "      <td>-0.759402</td>\n",
       "      <td>-0.412146</td>\n",
       "      <td>0.079378</td>\n",
       "      <td>0.803222</td>\n",
       "      <td>-0.328453</td>\n",
       "      <td>0.023672</td>\n",
       "      <td>0.058018</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155702</td>\n",
       "      <td>-0.524867</td>\n",
       "      <td>0.751315</td>\n",
       "      <td>2.278360</td>\n",
       "      <td>-0.295041</td>\n",
       "      <td>0.303778</td>\n",
       "      <td>0.164136</td>\n",
       "      <td>0.454016</td>\n",
       "      <td>-0.110623</td>\n",
       "      <td>1.276052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273717</td>\n",
       "      <td>-0.382037</td>\n",
       "      <td>-0.335380</td>\n",
       "      <td>-0.440796</td>\n",
       "      <td>0.280573</td>\n",
       "      <td>-0.727802</td>\n",
       "      <td>-0.087170</td>\n",
       "      <td>-0.158535</td>\n",
       "      <td>11.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76252</td>\n",
       "      <td>-16.772703</td>\n",
       "      <td>-14.426415</td>\n",
       "      <td>-5.606166</td>\n",
       "      <td>2.828980</td>\n",
       "      <td>-4.856624</td>\n",
       "      <td>1.538447</td>\n",
       "      <td>3.147259</td>\n",
       "      <td>-0.875503</td>\n",
       "      <td>1.767655</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.929283</td>\n",
       "      <td>-0.788744</td>\n",
       "      <td>-8.400941</td>\n",
       "      <td>0.775415</td>\n",
       "      <td>-0.619056</td>\n",
       "      <td>-0.272444</td>\n",
       "      <td>2.847241</td>\n",
       "      <td>1.520750</td>\n",
       "      <td>1644.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id         V1         V2        V3        V4        V5        V6  \\\n",
       "0  245376   1.812653  -0.476162 -0.338988  1.386750 -0.745965 -0.449870   \n",
       "1  202483  -1.014219   0.522775 -0.337978 -1.957797  3.578395  3.266965   \n",
       "2  221275  -0.600317   0.915481  0.835746 -0.621856  1.284060 -0.070605   \n",
       "3  155702  -0.524867   0.751315  2.278360 -0.295041  0.303778  0.164136   \n",
       "4   76252 -16.772703 -14.426415 -5.606166  2.828980 -4.856624  1.538447   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0 -0.492226  0.029904  1.129394  ...  0.252668  0.655719  0.090057 -0.136884   \n",
       "1  0.602857  0.644645 -0.305879  ...  0.147742  0.590740 -0.680551  0.745346   \n",
       "2  1.042698 -0.072551 -0.394966  ... -0.275582 -0.759402 -0.412146  0.079378   \n",
       "3  0.454016 -0.110623  1.276052  ... -0.273717 -0.382037 -0.335380 -0.440796   \n",
       "4  3.147259 -0.875503  1.767655  ... -2.929283 -0.788744 -8.400941  0.775415   \n",
       "\n",
       "        V25       V26       V27       V28      V29  Target  \n",
       "0 -0.172452 -0.556921  0.036490 -0.021575    79.00       0  \n",
       "1  1.119496  0.013520  0.004530 -0.132643     6.00       0  \n",
       "2  0.803222 -0.328453  0.023672  0.058018     1.50       0  \n",
       "3  0.280573 -0.727802 -0.087170 -0.158535    11.27       0  \n",
       "4 -0.619056 -0.272444  2.847241  1.520750  1644.77       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to see the data to get an understanding \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2483 entries, 0 to 2482\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      2483 non-null   int64  \n",
      " 1   V1      2250 non-null   float64\n",
      " 2   V2      2483 non-null   float64\n",
      " 3   V3      2483 non-null   float64\n",
      " 4   V4      2483 non-null   float64\n",
      " 5   V5      2483 non-null   float64\n",
      " 6   V6      2483 non-null   float64\n",
      " 7   V7      2483 non-null   float64\n",
      " 8   V8      2483 non-null   float64\n",
      " 9   V9      2483 non-null   float64\n",
      " 10  V10     2483 non-null   float64\n",
      " 11  V11     2483 non-null   float64\n",
      " 12  V12     2483 non-null   float64\n",
      " 13  V13     2483 non-null   float64\n",
      " 14  V14     2483 non-null   float64\n",
      " 15  V15     2483 non-null   float64\n",
      " 16  V16     2483 non-null   float64\n",
      " 17  V17     2483 non-null   float64\n",
      " 18  V18     2483 non-null   float64\n",
      " 19  V19     2483 non-null   float64\n",
      " 20  V20     2232 non-null   float64\n",
      " 21  V21     2483 non-null   float64\n",
      " 22  V22     2483 non-null   float64\n",
      " 23  V23     2483 non-null   float64\n",
      " 24  V24     2483 non-null   float64\n",
      " 25  V25     2483 non-null   float64\n",
      " 26  V26     2483 non-null   float64\n",
      " 27  V27     2483 non-null   float64\n",
      " 28  V28     2483 non-null   float64\n",
      " 29  V29     2483 non-null   float64\n",
      " 30  Target  2483 non-null   int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 601.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Find out number or rows, columns and datatypes of all variables \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106002</td>\n",
       "      <td>-0.049306</td>\n",
       "      <td>-0.308952</td>\n",
       "      <td>-0.150191</td>\n",
       "      <td>0.184762</td>\n",
       "      <td>-0.062611</td>\n",
       "      <td>0.091785</td>\n",
       "      <td>-0.026564</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>0.157150</td>\n",
       "      <td>0.016082</td>\n",
       "      <td>-0.014286</td>\n",
       "      <td>-0.203261</td>\n",
       "      <td>-0.036459</td>\n",
       "      <td>-0.018267</td>\n",
       "      <td>-0.035357</td>\n",
       "      <td>-0.011759</td>\n",
       "      <td>-0.013973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.106002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045613</td>\n",
       "      <td>0.238650</td>\n",
       "      <td>-0.128216</td>\n",
       "      <td>0.149235</td>\n",
       "      <td>0.014607</td>\n",
       "      <td>0.058938</td>\n",
       "      <td>-0.026575</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015946</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.161596</td>\n",
       "      <td>0.025835</td>\n",
       "      <td>0.038595</td>\n",
       "      <td>-0.051888</td>\n",
       "      <td>-0.127714</td>\n",
       "      <td>0.161877</td>\n",
       "      <td>-0.278976</td>\n",
       "      <td>-0.185015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>-0.049306</td>\n",
       "      <td>0.045613</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.048024</td>\n",
       "      <td>0.066016</td>\n",
       "      <td>-0.001432</td>\n",
       "      <td>-0.085869</td>\n",
       "      <td>-0.232418</td>\n",
       "      <td>0.053217</td>\n",
       "      <td>-0.115891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112762</td>\n",
       "      <td>-0.011440</td>\n",
       "      <td>0.138701</td>\n",
       "      <td>-0.027349</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>-0.023069</td>\n",
       "      <td>-0.091841</td>\n",
       "      <td>0.142665</td>\n",
       "      <td>-0.544283</td>\n",
       "      <td>0.195992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>-0.308952</td>\n",
       "      <td>0.238650</td>\n",
       "      <td>-0.048024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.146819</td>\n",
       "      <td>0.180421</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>0.136767</td>\n",
       "      <td>-0.083000</td>\n",
       "      <td>0.111096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015648</td>\n",
       "      <td>0.017954</td>\n",
       "      <td>0.066591</td>\n",
       "      <td>-0.009417</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>-0.010423</td>\n",
       "      <td>-0.105243</td>\n",
       "      <td>0.037479</td>\n",
       "      <td>-0.227559</td>\n",
       "      <td>-0.374903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>-0.150191</td>\n",
       "      <td>-0.128216</td>\n",
       "      <td>0.066016</td>\n",
       "      <td>-0.146819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082313</td>\n",
       "      <td>-0.058040</td>\n",
       "      <td>-0.055540</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>-0.108221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037808</td>\n",
       "      <td>-0.011248</td>\n",
       "      <td>-0.074991</td>\n",
       "      <td>-0.064187</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>0.028182</td>\n",
       "      <td>0.081911</td>\n",
       "      <td>-0.022143</td>\n",
       "      <td>0.102688</td>\n",
       "      <td>0.312903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.184762</td>\n",
       "      <td>0.149235</td>\n",
       "      <td>-0.001432</td>\n",
       "      <td>0.180421</td>\n",
       "      <td>-0.082313</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025338</td>\n",
       "      <td>0.052438</td>\n",
       "      <td>-0.048890</td>\n",
       "      <td>0.028536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052674</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>0.008635</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>-0.030131</td>\n",
       "      <td>0.030107</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>-0.024816</td>\n",
       "      <td>-0.363458</td>\n",
       "      <td>-0.167710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>-0.062611</td>\n",
       "      <td>0.014607</td>\n",
       "      <td>-0.085869</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>-0.058040</td>\n",
       "      <td>0.025338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070925</td>\n",
       "      <td>-0.069330</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088302</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.044203</td>\n",
       "      <td>-0.011469</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>-0.018641</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.228540</td>\n",
       "      <td>-0.120355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.091785</td>\n",
       "      <td>0.058938</td>\n",
       "      <td>-0.232418</td>\n",
       "      <td>0.136767</td>\n",
       "      <td>-0.055540</td>\n",
       "      <td>0.052438</td>\n",
       "      <td>0.070925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.053344</td>\n",
       "      <td>0.149379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028338</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>-0.003186</td>\n",
       "      <td>0.026326</td>\n",
       "      <td>-0.017525</td>\n",
       "      <td>-0.019956</td>\n",
       "      <td>-0.064976</td>\n",
       "      <td>-0.036404</td>\n",
       "      <td>0.414344</td>\n",
       "      <td>-0.270939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>-0.026564</td>\n",
       "      <td>-0.026575</td>\n",
       "      <td>0.053217</td>\n",
       "      <td>-0.083000</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>-0.048890</td>\n",
       "      <td>-0.069330</td>\n",
       "      <td>-0.053344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138539</td>\n",
       "      <td>-0.059503</td>\n",
       "      <td>-0.062360</td>\n",
       "      <td>0.032604</td>\n",
       "      <td>0.040018</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.057633</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>-0.090987</td>\n",
       "      <td>0.072134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.014134</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>-0.115891</td>\n",
       "      <td>0.111096</td>\n",
       "      <td>-0.108221</td>\n",
       "      <td>0.028536</td>\n",
       "      <td>0.034843</td>\n",
       "      <td>0.149379</td>\n",
       "      <td>-0.047900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029407</td>\n",
       "      <td>-0.009943</td>\n",
       "      <td>-0.043059</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>-0.024955</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.017287</td>\n",
       "      <td>-0.064089</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>-0.232330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.041763</td>\n",
       "      <td>0.132935</td>\n",
       "      <td>-0.162679</td>\n",
       "      <td>0.241818</td>\n",
       "      <td>-0.148472</td>\n",
       "      <td>0.119695</td>\n",
       "      <td>0.078622</td>\n",
       "      <td>0.224967</td>\n",
       "      <td>-0.054736</td>\n",
       "      <td>0.138106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062534</td>\n",
       "      <td>-0.050785</td>\n",
       "      <td>-0.033128</td>\n",
       "      <td>-0.037971</td>\n",
       "      <td>-0.037488</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>-0.041733</td>\n",
       "      <td>-0.109028</td>\n",
       "      <td>-0.053029</td>\n",
       "      <td>-0.448224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>-0.219083</td>\n",
       "      <td>-0.120230</td>\n",
       "      <td>0.058261</td>\n",
       "      <td>-0.188455</td>\n",
       "      <td>0.146493</td>\n",
       "      <td>-0.111462</td>\n",
       "      <td>-0.033933</td>\n",
       "      <td>-0.130512</td>\n",
       "      <td>0.024963</td>\n",
       "      <td>-0.110596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005709</td>\n",
       "      <td>-0.012040</td>\n",
       "      <td>-0.049255</td>\n",
       "      <td>-0.022688</td>\n",
       "      <td>0.024149</td>\n",
       "      <td>-0.025229</td>\n",
       "      <td>0.114915</td>\n",
       "      <td>-0.008953</td>\n",
       "      <td>0.042067</td>\n",
       "      <td>0.358506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.119889</td>\n",
       "      <td>0.121350</td>\n",
       "      <td>-0.134130</td>\n",
       "      <td>0.262103</td>\n",
       "      <td>-0.219359</td>\n",
       "      <td>0.101383</td>\n",
       "      <td>0.093871</td>\n",
       "      <td>0.211309</td>\n",
       "      <td>-0.090183</td>\n",
       "      <td>0.149086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003499</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.027320</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>-0.031093</td>\n",
       "      <td>-0.038035</td>\n",
       "      <td>-0.094905</td>\n",
       "      <td>-0.024368</td>\n",
       "      <td>-0.003616</td>\n",
       "      <td>-0.493831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>-0.045369</td>\n",
       "      <td>-0.027993</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>-0.048120</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>-0.027940</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>-0.004749</td>\n",
       "      <td>0.037252</td>\n",
       "      <td>-0.017887</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036796</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>-0.050641</td>\n",
       "      <td>-0.029466</td>\n",
       "      <td>-0.007189</td>\n",
       "      <td>0.043827</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.023268</td>\n",
       "      <td>-0.019926</td>\n",
       "      <td>0.002489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>-0.071924</td>\n",
       "      <td>0.118215</td>\n",
       "      <td>-0.111523</td>\n",
       "      <td>0.290048</td>\n",
       "      <td>-0.242955</td>\n",
       "      <td>0.142852</td>\n",
       "      <td>0.077512</td>\n",
       "      <td>0.207104</td>\n",
       "      <td>-0.081987</td>\n",
       "      <td>0.193741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043728</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>0.043764</td>\n",
       "      <td>0.032394</td>\n",
       "      <td>-0.039701</td>\n",
       "      <td>-0.016987</td>\n",
       "      <td>-0.104680</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>-0.006602</td>\n",
       "      <td>-0.599828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>-0.170863</td>\n",
       "      <td>-0.032225</td>\n",
       "      <td>-0.044510</td>\n",
       "      <td>-0.042316</td>\n",
       "      <td>-0.003529</td>\n",
       "      <td>-0.027638</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>0.017806</td>\n",
       "      <td>-0.015905</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006841</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>-0.027506</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>-0.030304</td>\n",
       "      <td>0.035449</td>\n",
       "      <td>-0.013480</td>\n",
       "      <td>-0.062583</td>\n",
       "      <td>0.032946</td>\n",
       "      <td>0.004597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.015783</td>\n",
       "      <td>0.075772</td>\n",
       "      <td>-0.115365</td>\n",
       "      <td>0.181669</td>\n",
       "      <td>-0.106318</td>\n",
       "      <td>0.123865</td>\n",
       "      <td>0.089122</td>\n",
       "      <td>0.209749</td>\n",
       "      <td>-0.066328</td>\n",
       "      <td>0.116941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052795</td>\n",
       "      <td>-0.047792</td>\n",
       "      <td>-0.013809</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>-0.055395</td>\n",
       "      <td>-0.004406</td>\n",
       "      <td>-0.058955</td>\n",
       "      <td>-0.008022</td>\n",
       "      <td>-0.002793</td>\n",
       "      <td>-0.361186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>-0.004735</td>\n",
       "      <td>0.211444</td>\n",
       "      <td>-0.121221</td>\n",
       "      <td>0.265299</td>\n",
       "      <td>-0.161811</td>\n",
       "      <td>0.198831</td>\n",
       "      <td>0.074465</td>\n",
       "      <td>0.242020</td>\n",
       "      <td>-0.065854</td>\n",
       "      <td>0.179512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020351</td>\n",
       "      <td>-0.043150</td>\n",
       "      <td>0.034836</td>\n",
       "      <td>-0.030089</td>\n",
       "      <td>-0.059864</td>\n",
       "      <td>-0.020776</td>\n",
       "      <td>-0.073058</td>\n",
       "      <td>-0.008038</td>\n",
       "      <td>-0.022046</td>\n",
       "      <td>-0.438157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.108321</td>\n",
       "      <td>0.112264</td>\n",
       "      <td>-0.011928</td>\n",
       "      <td>0.146607</td>\n",
       "      <td>-0.093861</td>\n",
       "      <td>0.110579</td>\n",
       "      <td>-0.015746</td>\n",
       "      <td>0.107366</td>\n",
       "      <td>-0.045485</td>\n",
       "      <td>0.081433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>-0.005033</td>\n",
       "      <td>0.082328</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>-0.001988</td>\n",
       "      <td>-0.033348</td>\n",
       "      <td>-0.058784</td>\n",
       "      <td>0.038706</td>\n",
       "      <td>-0.020533</td>\n",
       "      <td>-0.179531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.009758</td>\n",
       "      <td>-0.020820</td>\n",
       "      <td>0.028932</td>\n",
       "      <td>-0.051656</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>-0.084806</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>-0.026424</td>\n",
       "      <td>0.022819</td>\n",
       "      <td>-0.014497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>-0.001827</td>\n",
       "      <td>-0.011131</td>\n",
       "      <td>0.015067</td>\n",
       "      <td>-0.027025</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.023923</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>-0.006691</td>\n",
       "      <td>0.075097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>-0.035656</td>\n",
       "      <td>0.158838</td>\n",
       "      <td>0.299548</td>\n",
       "      <td>0.044290</td>\n",
       "      <td>-0.053365</td>\n",
       "      <td>0.101502</td>\n",
       "      <td>-0.087152</td>\n",
       "      <td>-0.232085</td>\n",
       "      <td>0.018390</td>\n",
       "      <td>-0.119165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017399</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.352078</td>\n",
       "      <td>-0.027695</td>\n",
       "      <td>0.125034</td>\n",
       "      <td>-0.035004</td>\n",
       "      <td>-0.107131</td>\n",
       "      <td>0.188164</td>\n",
       "      <td>-0.019059</td>\n",
       "      <td>0.066828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>0.056391</td>\n",
       "      <td>0.015946</td>\n",
       "      <td>0.112762</td>\n",
       "      <td>0.015648</td>\n",
       "      <td>-0.037808</td>\n",
       "      <td>0.052674</td>\n",
       "      <td>-0.088302</td>\n",
       "      <td>-0.028338</td>\n",
       "      <td>0.138539</td>\n",
       "      <td>0.029407</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.052529</td>\n",
       "      <td>0.116474</td>\n",
       "      <td>-0.005063</td>\n",
       "      <td>0.030389</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>-0.017794</td>\n",
       "      <td>0.019627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>0.157150</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>-0.011440</td>\n",
       "      <td>0.017954</td>\n",
       "      <td>-0.011248</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>0.030719</td>\n",
       "      <td>0.014045</td>\n",
       "      <td>-0.059503</td>\n",
       "      <td>-0.009943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017862</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>-0.029249</td>\n",
       "      <td>-0.020876</td>\n",
       "      <td>-0.012924</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>0.026907</td>\n",
       "      <td>0.013249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>0.016082</td>\n",
       "      <td>0.161596</td>\n",
       "      <td>0.138701</td>\n",
       "      <td>0.066591</td>\n",
       "      <td>-0.074991</td>\n",
       "      <td>0.008635</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>-0.003186</td>\n",
       "      <td>-0.062360</td>\n",
       "      <td>-0.043059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116474</td>\n",
       "      <td>-0.017862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>-0.010987</td>\n",
       "      <td>-0.039700</td>\n",
       "      <td>-0.059952</td>\n",
       "      <td>0.142485</td>\n",
       "      <td>0.046176</td>\n",
       "      <td>-0.025283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>-0.014286</td>\n",
       "      <td>0.025835</td>\n",
       "      <td>-0.027349</td>\n",
       "      <td>-0.009417</td>\n",
       "      <td>-0.064187</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.044203</td>\n",
       "      <td>0.026326</td>\n",
       "      <td>0.032604</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005063</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>-0.014019</td>\n",
       "      <td>-0.020466</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>-0.000480</td>\n",
       "      <td>-0.017834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>-0.203261</td>\n",
       "      <td>0.038595</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>-0.030131</td>\n",
       "      <td>-0.011469</td>\n",
       "      <td>-0.017525</td>\n",
       "      <td>0.040018</td>\n",
       "      <td>-0.024955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030389</td>\n",
       "      <td>-0.029249</td>\n",
       "      <td>-0.010987</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023555</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>0.032454</td>\n",
       "      <td>0.060482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>-0.036459</td>\n",
       "      <td>-0.051888</td>\n",
       "      <td>-0.023069</td>\n",
       "      <td>-0.010423</td>\n",
       "      <td>0.028182</td>\n",
       "      <td>0.030107</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>-0.019956</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>-0.020876</td>\n",
       "      <td>-0.039700</td>\n",
       "      <td>-0.014019</td>\n",
       "      <td>-0.023555</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024054</td>\n",
       "      <td>-0.043123</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>0.014279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>-0.018267</td>\n",
       "      <td>-0.127714</td>\n",
       "      <td>-0.091841</td>\n",
       "      <td>-0.105243</td>\n",
       "      <td>0.081911</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>-0.018641</td>\n",
       "      <td>-0.064976</td>\n",
       "      <td>0.057633</td>\n",
       "      <td>0.017287</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039137</td>\n",
       "      <td>-0.012924</td>\n",
       "      <td>-0.059952</td>\n",
       "      <td>-0.020466</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.024054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.270098</td>\n",
       "      <td>0.109559</td>\n",
       "      <td>0.104664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>-0.035357</td>\n",
       "      <td>0.161877</td>\n",
       "      <td>0.142665</td>\n",
       "      <td>0.037479</td>\n",
       "      <td>-0.022143</td>\n",
       "      <td>-0.024816</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>-0.036404</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>-0.064089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>0.142485</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>-0.043123</td>\n",
       "      <td>0.270098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032900</td>\n",
       "      <td>0.043068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V29</th>\n",
       "      <td>-0.011759</td>\n",
       "      <td>-0.278976</td>\n",
       "      <td>-0.544283</td>\n",
       "      <td>-0.227559</td>\n",
       "      <td>0.102688</td>\n",
       "      <td>-0.363458</td>\n",
       "      <td>0.228540</td>\n",
       "      <td>0.414344</td>\n",
       "      <td>-0.090987</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017794</td>\n",
       "      <td>0.026907</td>\n",
       "      <td>0.046176</td>\n",
       "      <td>-0.000480</td>\n",
       "      <td>0.032454</td>\n",
       "      <td>0.031573</td>\n",
       "      <td>0.109559</td>\n",
       "      <td>-0.032900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>-0.013973</td>\n",
       "      <td>-0.185015</td>\n",
       "      <td>0.195992</td>\n",
       "      <td>-0.374903</td>\n",
       "      <td>0.312903</td>\n",
       "      <td>-0.167710</td>\n",
       "      <td>-0.120355</td>\n",
       "      <td>-0.270939</td>\n",
       "      <td>0.072134</td>\n",
       "      <td>-0.232330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019627</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>-0.025283</td>\n",
       "      <td>-0.017834</td>\n",
       "      <td>0.060482</td>\n",
       "      <td>0.014279</td>\n",
       "      <td>0.104664</td>\n",
       "      <td>0.043068</td>\n",
       "      <td>0.015605</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id        V1        V2        V3        V4        V5        V6  \\\n",
       "Id      1.000000  0.106002 -0.049306 -0.308952 -0.150191  0.184762 -0.062611   \n",
       "V1      0.106002  1.000000  0.045613  0.238650 -0.128216  0.149235  0.014607   \n",
       "V2     -0.049306  0.045613  1.000000 -0.048024  0.066016 -0.001432 -0.085869   \n",
       "V3     -0.308952  0.238650 -0.048024  1.000000 -0.146819  0.180421  0.008765   \n",
       "V4     -0.150191 -0.128216  0.066016 -0.146819  1.000000 -0.082313 -0.058040   \n",
       "V5      0.184762  0.149235 -0.001432  0.180421 -0.082313  1.000000  0.025338   \n",
       "V6     -0.062611  0.014607 -0.085869  0.008765 -0.058040  0.025338  1.000000   \n",
       "V7      0.091785  0.058938 -0.232418  0.136767 -0.055540  0.052438  0.070925   \n",
       "V8     -0.026564 -0.026575  0.053217 -0.083000  0.037203 -0.048890 -0.069330   \n",
       "V9      0.014134  0.014293 -0.115891  0.111096 -0.108221  0.028536  0.034843   \n",
       "V10     0.041763  0.132935 -0.162679  0.241818 -0.148472  0.119695  0.078622   \n",
       "V11    -0.219083 -0.120230  0.058261 -0.188455  0.146493 -0.111462 -0.033933   \n",
       "V12     0.119889  0.121350 -0.134130  0.262103 -0.219359  0.101383  0.093871   \n",
       "V13    -0.045369 -0.027993  0.011601 -0.048120  0.000784 -0.027940  0.000500   \n",
       "V14    -0.071924  0.118215 -0.111523  0.290048 -0.242955  0.142852  0.077512   \n",
       "V15    -0.170863 -0.032225 -0.044510 -0.042316 -0.003529 -0.027638  0.021803   \n",
       "V16     0.015783  0.075772 -0.115365  0.181669 -0.106318  0.123865  0.089122   \n",
       "V17    -0.004735  0.211444 -0.121221  0.265299 -0.161811  0.198831  0.074465   \n",
       "V18     0.108321  0.112264 -0.011928  0.146607 -0.093861  0.110579 -0.015746   \n",
       "V19     0.009758 -0.020820  0.028932 -0.051656  0.004942 -0.084806  0.003313   \n",
       "V20    -0.035656  0.158838  0.299548  0.044290 -0.053365  0.101502 -0.087152   \n",
       "V21     0.056391  0.015946  0.112762  0.015648 -0.037808  0.052674 -0.088302   \n",
       "V22     0.157150  0.013514 -0.011440  0.017954 -0.011248  0.008160  0.030719   \n",
       "V23     0.016082  0.161596  0.138701  0.066591 -0.074991  0.008635  0.002211   \n",
       "V24    -0.014286  0.025835 -0.027349 -0.009417 -0.064187  0.004263  0.044203   \n",
       "V25    -0.203261  0.038595  0.027026  0.001164  0.023302 -0.030131 -0.011469   \n",
       "V26    -0.036459 -0.051888 -0.023069 -0.010423  0.028182  0.030107  0.002508   \n",
       "V27    -0.018267 -0.127714 -0.091841 -0.105243  0.081911  0.007896 -0.018641   \n",
       "V28    -0.035357  0.161877  0.142665  0.037479 -0.022143 -0.024816  0.006421   \n",
       "V29    -0.011759 -0.278976 -0.544283 -0.227559  0.102688 -0.363458  0.228540   \n",
       "Target -0.013973 -0.185015  0.195992 -0.374903  0.312903 -0.167710 -0.120355   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "Id      0.091785 -0.026564  0.014134  ...  0.056391  0.157150  0.016082   \n",
       "V1      0.058938 -0.026575  0.014293  ...  0.015946  0.013514  0.161596   \n",
       "V2     -0.232418  0.053217 -0.115891  ...  0.112762 -0.011440  0.138701   \n",
       "V3      0.136767 -0.083000  0.111096  ...  0.015648  0.017954  0.066591   \n",
       "V4     -0.055540  0.037203 -0.108221  ... -0.037808 -0.011248 -0.074991   \n",
       "V5      0.052438 -0.048890  0.028536  ...  0.052674  0.008160  0.008635   \n",
       "V6      0.070925 -0.069330  0.034843  ... -0.088302  0.030719  0.002211   \n",
       "V7      1.000000 -0.053344  0.149379  ... -0.028338  0.014045 -0.003186   \n",
       "V8     -0.053344  1.000000 -0.047900  ...  0.138539 -0.059503 -0.062360   \n",
       "V9      0.149379 -0.047900  1.000000  ...  0.029407 -0.009943 -0.043059   \n",
       "V10     0.224967 -0.054736  0.138106  ...  0.062534 -0.050785 -0.033128   \n",
       "V11    -0.130512  0.024963 -0.110596  ... -0.005709 -0.012040 -0.049255   \n",
       "V12     0.211309 -0.090183  0.149086  ... -0.003499  0.006980  0.027320   \n",
       "V13    -0.004749  0.037252 -0.017887  ... -0.036796  0.015718 -0.050641   \n",
       "V14     0.207104 -0.081987  0.193741  ... -0.043728  0.020562  0.043764   \n",
       "V15     0.017806 -0.015905  0.003407  ... -0.006841  0.000668 -0.027506   \n",
       "V16     0.209749 -0.066328  0.116941  ... -0.052795 -0.047792 -0.013809   \n",
       "V17     0.242020 -0.065854  0.179512  ... -0.020351 -0.043150  0.034836   \n",
       "V18     0.107366 -0.045485  0.081433  ...  0.010631 -0.005033  0.082328   \n",
       "V19    -0.026424  0.022819 -0.014497  ...  0.009845 -0.001827 -0.011131   \n",
       "V20    -0.232085  0.018390 -0.119165  ...  0.017399  0.092105  0.352078   \n",
       "V21    -0.028338  0.138539  0.029407  ...  1.000000 -0.052529  0.116474   \n",
       "V22     0.014045 -0.059503 -0.009943  ... -0.052529  1.000000 -0.017862   \n",
       "V23    -0.003186 -0.062360 -0.043059  ...  0.116474 -0.017862  1.000000   \n",
       "V24     0.026326  0.032604  0.023978  ... -0.005063  0.001441  0.001396   \n",
       "V25    -0.017525  0.040018 -0.024955  ...  0.030389 -0.029249 -0.010987   \n",
       "V26    -0.019956  0.002814  0.001089  ...  0.004286 -0.020876 -0.039700   \n",
       "V27    -0.064976  0.057633  0.017287  ... -0.039137 -0.012924 -0.059952   \n",
       "V28    -0.036404  0.039447 -0.064089  ...  0.005493 -0.001360  0.142485   \n",
       "V29     0.414344 -0.090987  0.002722  ... -0.017794  0.026907  0.046176   \n",
       "Target -0.270939  0.072134 -0.232330  ...  0.019627  0.013249 -0.025283   \n",
       "\n",
       "             V24       V25       V26       V27       V28       V29    Target  \n",
       "Id     -0.014286 -0.203261 -0.036459 -0.018267 -0.035357 -0.011759 -0.013973  \n",
       "V1      0.025835  0.038595 -0.051888 -0.127714  0.161877 -0.278976 -0.185015  \n",
       "V2     -0.027349  0.027026 -0.023069 -0.091841  0.142665 -0.544283  0.195992  \n",
       "V3     -0.009417  0.001164 -0.010423 -0.105243  0.037479 -0.227559 -0.374903  \n",
       "V4     -0.064187  0.023302  0.028182  0.081911 -0.022143  0.102688  0.312903  \n",
       "V5      0.004263 -0.030131  0.030107  0.007896 -0.024816 -0.363458 -0.167710  \n",
       "V6      0.044203 -0.011469  0.002508 -0.018641  0.006421  0.228540 -0.120355  \n",
       "V7      0.026326 -0.017525 -0.019956 -0.064976 -0.036404  0.414344 -0.270939  \n",
       "V8      0.032604  0.040018  0.002814  0.057633  0.039447 -0.090987  0.072134  \n",
       "V9      0.023978 -0.024955  0.001089  0.017287 -0.064089  0.002722 -0.232330  \n",
       "V10    -0.037971 -0.037488  0.010623 -0.041733 -0.109028 -0.053029 -0.448224  \n",
       "V11    -0.022688  0.024149 -0.025229  0.114915 -0.008953  0.042067  0.358506  \n",
       "V12     0.004035 -0.031093 -0.038035 -0.094905 -0.024368 -0.003616 -0.493831  \n",
       "V13    -0.029466 -0.007189  0.043827  0.023490  0.023268 -0.019926  0.002489  \n",
       "V14     0.032394 -0.039701 -0.016987 -0.104680 -0.003888 -0.006602 -0.599828  \n",
       "V15    -0.011886 -0.030304  0.035449 -0.013480 -0.062583  0.032946  0.004597  \n",
       "V16     0.008752 -0.055395 -0.004406 -0.058955 -0.008022 -0.002793 -0.361186  \n",
       "V17    -0.030089 -0.059864 -0.020776 -0.073058 -0.008038 -0.022046 -0.438157  \n",
       "V18     0.003528 -0.001988 -0.033348 -0.058784  0.038706 -0.020533 -0.179531  \n",
       "V19     0.015067 -0.027025  0.003887  0.023923  0.006858 -0.006691  0.075097  \n",
       "V20    -0.027695  0.125034 -0.035004 -0.107131  0.188164 -0.019059  0.066828  \n",
       "V21    -0.005063  0.030389  0.004286 -0.039137  0.005493 -0.017794  0.019627  \n",
       "V22     0.001441 -0.029249 -0.020876 -0.012924 -0.001360  0.026907  0.013249  \n",
       "V23     0.001396 -0.010987 -0.039700 -0.059952  0.142485  0.046176 -0.025283  \n",
       "V24     1.000000  0.002914 -0.014019 -0.020466  0.014272 -0.000480 -0.017834  \n",
       "V25     0.002914  1.000000 -0.023555  0.008346 -0.008308  0.032454  0.060482  \n",
       "V26    -0.014019 -0.023555  1.000000  0.024054 -0.043123  0.031573  0.014279  \n",
       "V27    -0.020466  0.008346  0.024054  1.000000  0.270098  0.109559  0.104664  \n",
       "V28     0.014272 -0.008308 -0.043123  0.270098  1.000000 -0.032900  0.043068  \n",
       "V29    -0.000480  0.032454  0.031573  0.109559 -0.032900  1.000000  0.015605  \n",
       "Target -0.017834  0.060482  0.014279  0.104664  0.043068  0.015605  1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To find corr between variables and drop highly correlated values if any \n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1 : 233\n",
      "V20 : 251\n"
     ]
    }
   ],
   "source": [
    "# Column with Null Values and it's count in Train dataset\n",
    "null_values= data.isnull().sum()\n",
    "for key,value in null_values.items():\n",
    "    if value >0:\n",
    "        print(key,\":\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1 : 2499\n",
      "V20 : 2504\n"
     ]
    }
   ],
   "source": [
    "# Column with Null Values and it's count in test dataset \n",
    "null_values= test.isnull().sum()\n",
    "for key,value in null_values.items():\n",
    "    if value >0:\n",
    "        print(key,\":\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id : 2483\n",
      "V1 : 2250\n",
      "V2 : 2482\n",
      "V3 : 2482\n",
      "V4 : 2482\n",
      "V5 : 2482\n",
      "V6 : 2482\n",
      "V7 : 2482\n",
      "V8 : 2482\n",
      "V9 : 2482\n",
      "V10 : 2482\n",
      "V11 : 2482\n",
      "V12 : 2482\n",
      "V13 : 2482\n",
      "V14 : 2482\n",
      "V15 : 2482\n",
      "V16 : 2482\n",
      "V17 : 2482\n",
      "V18 : 2482\n",
      "V19 : 2482\n",
      "V20 : 2231\n",
      "V21 : 2482\n",
      "V22 : 2482\n",
      "V23 : 2482\n",
      "V24 : 2482\n",
      "V25 : 2482\n",
      "V26 : 2482\n",
      "V27 : 2482\n",
      "V28 : 2482\n",
      "V29 : 1452\n",
      "Target : 2\n"
     ]
    }
   ],
   "source": [
    "#No of unique values in each column in train set \n",
    "total_unique_values= data.nunique()\n",
    "for key,value in total_unique_values.items():\n",
    "    if value >0:\n",
    "        print(key,\":\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1738, 30), (745, 30))"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split Train dataset into train and test 70-30\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['Target'], axis=1),\n",
    "                                                    data['Target'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24846, 30)\n"
     ]
    }
   ],
   "source": [
    "#number of columns in test to check if they match with train dataset\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine import missing_data_imputers as mdi\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "    #Replacing Null values with the column median values \n",
    "preprocess = Pipeline([\n",
    "    ('imputer_num', mdi.MeanMedianImputer(imputation_method='median',\n",
    "                                          variables=['V1','V20'])),\n",
    "      # feature Scaling\n",
    "   ('scaler', StandardScaler())\n",
    "     \n",
    "     \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('imputer_num',\n",
       "                 MeanMedianImputer(imputation_method='median',\n",
       "                                   variables=['V1', 'V20'])),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=preprocess.transform(X_train)\n",
    "X_test=preprocess.transform(X_test)\n",
    "X_testt=preprocess.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f2 score \n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.7911340852130325\n",
      "Best Mean Cross Validation Score is {'C': 1, 'multi_class': 'auto', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Train score is 0.913978494623656\n",
      "Test score is 0.9615384615384615\n"
     ]
    }
   ],
   "source": [
    "#logistic regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logreg=LogisticRegression(max_iter=10000)\n",
    "\n",
    "logreg_param= {\n",
    "     'C': [0.01,0.1,1],\n",
    "      'penalty':['l2','l1'],\n",
    "     'solver' :['newton-cg','lbfgs', 'sag'],\n",
    "     'multi_class':['auto']\n",
    "}\n",
    "logreg_grid = GridSearchCV(logreg,logreg_param,cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "logreg_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {logreg_grid.best_score_}')\n",
    "print(f'Best Mean Cross Validation Score is {logreg_grid.best_params_}')\n",
    "print(f'Train score is {logreg_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {logreg_grid.score(X_test,y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.745\n",
      "Decision Tree parameters:  {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'splitter': 'best'}\n",
      "Train score:  0.9042553191489363\n",
      "Test Score: 1.0\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "param_dtree = {'max_depth': [1,2,3,5],\n",
    "               'splitter':['random','best'],\n",
    "               'max_features':['auto','log2','sqrt'],\n",
    "               'criterion':['gini','entropy'],\n",
    "              \n",
    "              }\n",
    "\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree, param_dtree, cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {:.3f}\".format(grid_dtree.best_score_))\n",
    "print('Decision Tree parameters: ', grid_dtree.best_params_)\n",
    "print('Train score: ', grid_dtree.score(X_train, y_train))\n",
    "print(\"Test Score:\", grid_dtree.score(X_test,y_test))\n",
    "\n",
    "X_test_preds = grid_dtree.predict(X_testt)\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame({'Id': test.Id, 'Target':X_test_preds }).to_csv('solution_base15.csv', index =False)  \n",
    "print(\"Done :D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.817\n",
      "KNN parameters:  {'algorithm': 'auto', 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "Train score:  0.8152173913043478\n",
      "KNN Test Performance:  1.0\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_knn = {\n",
    "             'n_neighbors': [3], \n",
    "             'weights': ['uniform','distance'],\n",
    "             'algorithm' :['auto'],\n",
    "             'p':[2,3]\n",
    "             \n",
    "            }\n",
    "\n",
    "#apply grid search\n",
    "\n",
    "grid_knn = GridSearchCV(knn, param_knn, cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.3f}\".format(grid_knn.best_score_))\n",
    "print('KNN parameters: ', grid_knn.best_params_)\n",
    "print('Train score: ', grid_knn.score(X_train, y_train))\n",
    "print(\"KNN Test Performance: \", grid_knn.score(X_test,y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.906265664160401\n",
      "{'C': 0.001, 'multi_class': 'crammer_singer', 'penalty': 'l1'}\n",
      "train score:  0.9042553191489363\n",
      "test score:  1.0\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#Simple SVM \n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#svc = SVC()\n",
    "\n",
    "svc = LinearSVC(max_iter=100000)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "#define a list of parameters\n",
    "param_svc_kernel = {'C': [0.001,0.01,0.1,1], \n",
    "                    'penalty':['l1','l2'],\n",
    "                    'multi_class':['ovr','crammer_singer']\n",
    "                  \n",
    "                   }\n",
    "\n",
    "#apply grid search\n",
    "grid_svc = GridSearchCV(svc,param_svc_kernel, cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "print('Best cross-validation score:', grid_svc.best_score_)\n",
    "print(grid_svc.best_params_)\n",
    "print('train score: ', grid_svc.score(X_train, y_train))\n",
    "print('test score: ', grid_svc.score(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "X_test_preds = grid_svc.predict(X_testt)\n",
    "pd.DataFrame({'Id': test.Id, 'Target':X_test_preds }).to_csv('solution_base3.csv', index =False)  \n",
    "print(\"Done :D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.906265664160401\n",
      "{'C': 10.0, 'gamma': 0.001}\n",
      "train score:  0.913978494623656\n",
      "test score:  1.0\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#SVM with kernel='rbf'\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "svc_kernel = SVC(kernel = 'rbf')\n",
    "\n",
    "#define a list of parameters\n",
    "C_range = 10. ** np.arange(-3, 8)\n",
    "gamma_range = 10. ** np.arange(-5, 4)\n",
    "\n",
    "param_svc_kernel = {'C': C_range,\n",
    "                    'gamma':gamma_range}\n",
    "\n",
    "#apply grid search\n",
    "grid_svc_rbf = GridSearchCV(svc_kernel, param_svc_kernel, cv=5, n_jobs=-1,scoring=ftwo_scorer)\n",
    "grid_svc_rbf.fit(X_train, y_train)\n",
    "print('Best cross-validation score:', grid_svc_rbf.best_score_)\n",
    "print(grid_svc_rbf.best_params_)\n",
    "print('train score: ', grid_svc_rbf.score(X_train, y_train))\n",
    "print('test score: ', grid_svc_rbf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "X_test_preds = grid_svc_rbf.predict(X_testt)\n",
    "pd.DataFrame({'Id': test.Id, 'Target':X_test_preds }).to_csv('solution_base.csv', index =False)  \n",
    "print(\"Done :D\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.6660179861418251\n",
      "Best param {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Train score is 0.8152173913043478\n",
      "Test score is 0.8333333333333334\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc =RandomForestClassifier(random_state=0)\n",
    "rfc_param = { \n",
    "     'n_estimators': [100],\n",
    "     'max_features': ['auto','sqrt','log2'],\n",
    "     'max_depth' : [1,2,3,5],\n",
    "     'criterion' :['gini', 'entropy'],\n",
    "     'min_samples_split' :[2],\n",
    "     'min_samples_leaf':[3],\n",
    "\n",
    "}\n",
    "rfc_grid = GridSearchCV(rfc, rfc_param,cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "rfc_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {rfc_grid.best_score_}')\n",
    "print(f'Best param {rfc_grid.best_params_}')\n",
    "print(f'Train score is {rfc_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {rfc_grid.score(X_test,y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.6255417956656346\n",
      "Best param {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Train score is 0.8695652173913043\n",
      "Test score is 0.6521739130434783\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#Extra trees\n",
    "from  sklearn.ensemble import ExtraTreesClassifier\n",
    "etc= ExtraTreesClassifier(random_state=0)\n",
    "etc_param = { \n",
    "    'n_estimators': [100],\n",
    "    'max_features': ['auto','sqrt','log2'],\n",
    "    'max_depth' : [1,2,3,5],\n",
    "    'criterion' :['gini','entropy'],\n",
    "    'min_samples_split':[2,3],\n",
    "  \n",
    "\n",
    "}\n",
    "etc_grid = GridSearchCV(etc, etc_param,cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "etc_grid.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best Mean Cross Validation Score is {etc_grid.best_score_}')\n",
    "print(f'Best param {etc_grid.best_params_}')\n",
    "print(f'Train score is {etc_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {etc_grid.score(X_test,y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.8236842105263158\n",
      "Best param {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200, 'subsample': 1}\n",
      "Train score is 0.913978494623656\n",
      "Test score is 0.9615384615384615\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#Gradient boost\n",
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc= GradientBoostingClassifier(random_state=0)\n",
    "gbc_param = {\n",
    "              'max_depth' : [1],\n",
    "              'n_estimators' : [200],\n",
    "              'learning_rate' : [0.1],\n",
    "              'subsample':[1],\n",
    "              'min_samples_split':[2],\n",
    "              'min_samples_leaf':[4],\n",
    "              'max_features': ['auto','sqrt','log2'],\n",
    "              'loss': ['deviance','exponential'],\n",
    "    \n",
    "    \n",
    "             }\n",
    "gbc_grid = GridSearchCV(gbc, gbc_param,cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "gbc_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {gbc_grid.best_score_}')\n",
    "print(f'Best param {gbc_grid.best_params_}')\n",
    "print(f'Train score is {gbc_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {gbc_grid.score(X_test,y_test)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.8094820384294069\n",
      "Best param {'learning_rate': 0.01, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 150}\n",
      "Train score is 0.8241758241758242\n",
      "Test score is 0.8333333333333334\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#XGBoost \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "xgbc= XGBClassifier(random_state=0,early_stopping_rounds=4,objective= 'binary:logistic')\n",
    "xgbc_param = {\n",
    "              'max_depth' : [1,2,3,5],\n",
    "              'n_estimators' : [150],\n",
    "              'learning_rate' : [0.01,0.1,0.5],\n",
    "              'min_child_weight' : [3],\n",
    "             # 'subsample':[0.8]\n",
    "             }\n",
    "xgbc_grid = GridSearchCV(xgbc, xgbc_param,cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "xgbc_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {xgbc_grid.best_score_}')\n",
    "print(f'Best param {xgbc_grid.best_params_}')\n",
    "print(f'Train score is {xgbc_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {xgbc_grid.score(X_test,y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.06134344811097836\n",
      "Best param {'strategy': 'uniform'}\n",
      "Train score is 0.05241090146750525\n",
      "Test score is 0.04705882352941176\n"
     ]
    }
   ],
   "source": [
    "#Dummy Classifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    " \n",
    "dummy= DummyClassifier()\n",
    "\n",
    "dummy_param= {\n",
    "   \"strategy\":['prior','uniform','stratified','most_frequent','constant']\n",
    "}\n",
    "\n",
    "\n",
    "dummy_grid = GridSearchCV(dummy, dummy_param,cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "dummy_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {dummy_grid.best_score_}')\n",
    "print(f'Best param {dummy_grid.best_params_}')\n",
    "print(f'Train score is {dummy_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {dummy_grid.score(X_test,y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost Sensitive Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.6744916804901324\n",
      "Best param {'C': 0.01, 'class_weight': {0: 1, 1: 10}, 'max_iter': 200, 'multi_class': 'auto', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Train score is 0.7575757575757575\n",
      "Test score is 0.9090909090909091\n",
      "train rmse: 0.07955572841757301\n",
      "test rmse: 0.08192319205190404\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "logreg=LogisticRegression(max_iter=1000)\n",
    "\n",
    "logreg_param= {\n",
    "    'C': [0.01],\n",
    "    'penalty':['l1', 'l2'],\n",
    "    'class_weight' :['balanced','none'],\n",
    "    'solver' :['lbfgs'],\n",
    "    'max_iter' :[200],\n",
    "    'multi_class':['auto'],\n",
    "    'class_weight': [{0:1,1:10}]\n",
    "}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=7, n_repeats=3, random_state=1)\n",
    "\n",
    "clogreg_grid = GridSearchCV(logreg, logreg_param,cv=cv,n_jobs=-1,scoring=ftwo_scorer)\n",
    "clogreg_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {clogreg_grid.best_score_}')\n",
    "print(f'Best param {clogreg_grid.best_params_}')\n",
    "print(f'Train score is {clogreg_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {clogreg_grid.score(X_test,y_test)}')\n",
    "\n",
    "\n",
    "\n",
    "X_train_preds = clogreg_grid.predict(X_train)\n",
    "X_test_preds = clogreg_grid.predict(X_test)\n",
    "\n",
    "print('train rmse: {}'.format(sqrt(mean_squared_error(y_train, X_train_preds))))\n",
    "print('test rmse: {}'.format(sqrt(mean_squared_error(y_test, X_test_preds))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.673\n",
      "Decision Tree parameters:  {'class_weight': {0: 1, 1: 1}, 'max_depth': 3, 'max_features': 'log2', 'splitter': 'best'}\n",
      "Train score:  0.7142857142857142\n",
      "Test Score: 0.6382978723404255\n",
      "train rmse: 0.0719608639321375\n",
      "test rmse: 0.08192319205190404\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "\n",
    "#define a list of parameters\n",
    "param_dtree = {'max_depth': [3],\n",
    "              'class_weight': [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}],\n",
    "               'splitter':['random','best'],\n",
    "               'max_features':['auto','sqrt','log2']\n",
    "              }\n",
    "\n",
    "cgrid_dtree = GridSearchCV(dtree, param_dtree, cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "cgrid_dtree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Mean Cross-validation score: {:.3f}\".format(cgrid_dtree.best_score_))\n",
    "print('Decision Tree parameters: ', cgrid_dtree.best_params_)\n",
    "print('Train score: ', cgrid_dtree.score(X_train, y_train))\n",
    "print(\"Test Score:\", cgrid_dtree.score(X_test,y_test))\n",
    "\n",
    "X_train_preds = cgrid_dtree.predict(X_train)\n",
    "X_test_preds = cgrid_dtree.predict(X_test)\n",
    "\n",
    "print('train rmse: {}'.format(sqrt(mean_squared_error(y_train, X_train_preds))))\n",
    "print('test rmse: {}'.format(sqrt(mean_squared_error(y_test, X_test_preds))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.6836496836496837\n",
      "{'C': 0.01, 'class_weight': {0: 1, 1: 1}, 'multi_class': 'crammer_singer', 'penalty': 'l1'}\n",
      "train score:  0.703125\n",
      "test score:  0.980392156862745\n",
      "train rmse: 0.07955572841757301\n",
      "test rmse: 0.03663716527236559\n"
     ]
    }
   ],
   "source": [
    "#Simple SVM \n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#svc = SVC()\n",
    "\n",
    "svc = LinearSVC(max_iter=100000)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#define a list of parameters\n",
    "param_svc_kernel = {'C': [0.01],\n",
    "                    'class_weight': [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}],\n",
    "                    'penalty':['l1','l2'],\n",
    "                    'multi_class':['ovr','crammer_singer']\n",
    "                   }\n",
    "\n",
    "#apply grid search\n",
    "\n",
    "cgrid_svc = GridSearchCV(svc,param_svc_kernel, cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "cgrid_svc.fit(X_train, y_train)\n",
    "print('Best cross-validation score:', cgrid_svc.best_score_)\n",
    "print(cgrid_svc.best_params_)\n",
    "print('train score: ', cgrid_svc.score(X_train, y_train))\n",
    "print('test score: ', cgrid_svc.score(X_test, y_test))\n",
    "\n",
    "X_train_preds = cgrid_svc.predict(X_train)\n",
    "X_test_preds = cgrid_svc.predict(X_test)\n",
    "\n",
    "print('train rmse: {}'.format(sqrt(mean_squared_error(y_train, X_train_preds))))\n",
    "print('test rmse: {}'.format(sqrt(mean_squared_error(y_test, X_test_preds))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.6991216512955644\n",
      "Best param {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2'}\n",
      "Train score is 0.8076923076923078\n",
      "Test score is 0.8823529411764706\n",
      "train rmse: 0.06346351669793114\n",
      "test rmse: 0.06345743169703524\n"
     ]
    }
   ],
   "source": [
    "#Random Forest \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "crf = RandomForestClassifier(n_estimators=150)\n",
    "crf_param={\n",
    "\n",
    "                'max_depth' : [2,3,5],\n",
    "                'criterion' : [\"gini\",\"entropy\"],\n",
    "                'max_features': [\"auto\",\"sqrt\",\"log2\"],        \n",
    "                'class_weight':[\"balanced\"]\n",
    "    \n",
    "}\n",
    "crf_grid = GridSearchCV(crf, crf_param,cv=5,n_jobs=-1, scoring=ftwo_scorer)\n",
    "\n",
    "crf_grid.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best Mean Cross Validation Score is {crf_grid.best_score_}')\n",
    "print(f'Best param {crf_grid.best_params_}')\n",
    "print(f'Train score is {crf_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {crf_grid.score(X_test,y_test)}')\n",
    "\n",
    "X_train_preds = crf_grid.predict(X_train)\n",
    "X_test_preds = crf_grid.predict(X_test)\n",
    "\n",
    "print('train rmse: {}'.format(sqrt(mean_squared_error(y_train, X_train_preds))))\n",
    "print('test rmse: {}'.format(sqrt(mean_squared_error(y_test, X_test_preds))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.6864468864468865\n",
      "Best param {'class_weight': {0: 100, 1: 1}, 'learning_rate': 0.1, 'max_depth': 1, 'min_child_weight': 2, 'n_estimators': 150, 'subsample': 0.5}\n",
      "Train score is 0.7421875000000001\n",
      "Test score is 0.9615384615384615\n",
      "train rmse: 0.0719608639321375\n",
      "test rmse: 0.05181277601508398\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgbc= XGBClassifier(random_state=0,early_stopping_rounds=2,objective= 'binary:logistic')\n",
    "\n",
    "param_grid = { \n",
    " # 'scale_pos_weight': [1, 10],\n",
    "              'max_depth' : [1,2,3,5],\n",
    "              'n_estimators' : [150],\n",
    "              'learning_rate' : [0.1],\n",
    "              'min_child_weight' : [1,2],\n",
    "              'subsample':[0.5],\n",
    "              'class_weight': [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}],\n",
    "\n",
    "}\n",
    "\n",
    "cxgbc_grid = GridSearchCV(xgbc, param_grid,cv=10,n_jobs=-1, scoring=ftwo_scorer)\n",
    "cxgbc_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {cxgbc_grid.best_score_}')\n",
    "print(f'Best param {cxgbc_grid.best_params_}')\n",
    "print(f'Train score is {cxgbc_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {cxgbc_grid.score(X_test,y_test)}')\n",
    "\n",
    "\n",
    "X_train_preds = cxgbc_grid.predict(X_train)\n",
    "X_test_preds = cxgbc_grid.predict(X_test)\n",
    "\n",
    "print('train rmse: {}'.format(sqrt(mean_squared_error(y_train, X_train_preds))))\n",
    "print('test rmse: {}'.format(sqrt(mean_squared_error(y_test, X_test_preds))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.7160528682267813\n",
      "Best param {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Train score is 0.7835820895522388\n",
      "Test score is 0.9433962264150945\n",
      "train rmse: 0.07955572841757301\n",
      "test rmse: 0.06345743169703524\n"
     ]
    }
   ],
   "source": [
    "#Extratrees\n",
    "from  sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "etc= ExtraTreesClassifier(random_state=0,class_weight='balanced')\n",
    "etc_param = { \n",
    "    'n_estimators': [100],\n",
    "    'max_features': ['auto','sqrt','log2'],\n",
    "    'max_depth' : [1,2,3,5],\n",
    "    'criterion' :['gini','entropy'],\n",
    "    'min_samples_split':[2,3],\n",
    "  \n",
    "}\n",
    "cetc_grid = GridSearchCV(etc, etc_param,cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "cetc_grid.fit(X_train,y_train)\n",
    "\n",
    "print(f'Best Mean Cross Validation Score is {cetc_grid.best_score_}')\n",
    "print(f'Best param {cetc_grid.best_params_}')\n",
    "print(f'Train score is {cetc_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {cetc_grid.score(X_test,y_test)}')\n",
    "\n",
    "X_train_preds = cetc_grid.predict(X_train)\n",
    "X_test_preds = cetc_grid.predict(X_test)\n",
    "\n",
    "print('train rmse: {}'.format(sqrt(mean_squared_error(y_train, X_train_preds))))\n",
    "print('test rmse: {}'.format(sqrt(mean_squared_error(y_test, X_test_preds))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean f2: 0.577\n"
     ]
    }
   ],
   "source": [
    "#Bagging Decision Tree with undersampling\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "b_dtree = BalancedBaggingClassifier()\n",
    "\n",
    "scores = cross_val_score(b_dtree, X_train, y_train, scoring=ftwo_scorer, cv=5, n_jobs=-1)\n",
    "\n",
    "\n",
    "print('Mean f2: %.3f' % scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean scores of all cost sensitive algorithms\n",
      "etc 0.563338959890684\n",
      "b_tree 0.5525844184139883\n",
      "xgbc 0.637052685778323\n",
      "randomforest 0.6914293436032567\n",
      "svc 0.6556433904259992\n",
      "dtree 0.6619252432155658\n",
      "logreg 0.6223100570926658\n"
     ]
    }
   ],
   "source": [
    "scores1= cross_val_score(etc, X_train, y_train, scoring=ftwo_scorer, cv=5, n_jobs=-1)\n",
    "scores2= cross_val_score(b_dtree, X_train, y_train, scoring=ftwo_scorer, cv=5, n_jobs=-1)\n",
    "scores3= cross_val_score(xgbc, X_train, y_train, scoring=ftwo_scorer, cv=5, n_jobs=-1)\n",
    "scores4= cross_val_score(crf, X_train, y_train, scoring=ftwo_scorer, cv=5, n_jobs=-1)\n",
    "scores5= cross_val_score(svc, X_train, y_train, scoring=ftwo_scorer, cv=5, n_jobs=-1)\n",
    "scores6= cross_val_score(dtree, X_train, y_train, scoring=ftwo_scorer, cv=5, n_jobs=-1)\n",
    "scores7= cross_val_score(logreg, X_train, y_train, scoring=ftwo_scorer, cv=5, n_jobs=-1)\n",
    "print('mean scores of all cost sensitive algorithms')\n",
    "print(f'etc {scores1.mean()}')\n",
    "print(f'b_tree {scores2.mean()}')\n",
    "print(f'xgbc {scores3.mean()}')\n",
    "print(f'randomforest {scores4.mean()}')\n",
    "print(f'svc {scores5.mean()}')\n",
    "print(f'dtree {scores6.mean()}')\n",
    "print(f'logreg {scores7.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.\tData Sampling Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.699\n",
      "Best parameters: {'lg__C': 0.0001, 'lg__class_weight': 'balanced', 'lg__max_iter': 150, 'lg__multi_class': 'multinomial', 'lg__penalty': 'l2', 'lg__solver': 'newton-cg', 'smote__k_neighbors': 2}\n",
      "Train score is 0.7835820895522388\n",
      "Test score is 0.9259259259259259\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as p\n",
    "\n",
    "pipe_roc_lg = p([('smote',SMOTE()),('lg',LogisticRegression())])\n",
    "param_roc_lg = {'smote__k_neighbors': [2],\n",
    "               'lg__C': [0.0001],\n",
    "                'lg__penalty':['l1', 'l2'],\n",
    "               'lg__max_iter':[150],\n",
    "               'lg__solver':['newton-cg'],\n",
    "                'lg__class_weight':[\"balanced\"],\n",
    "               'lg__multi_class':['auto', 'ovr', 'multinomial']\n",
    "               }\n",
    "\n",
    "ogrid_lg= GridSearchCV(pipe_roc_lg,param_roc_lg, cv=5, n_jobs=-1, scoring=ftwo_scorer)\n",
    "ogrid_lg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Mean cross-validation score: {:.3f}\".format(ogrid_lg.best_score_))\n",
    "print(\"Best parameters: {}\".format(ogrid_lg.best_params_))\n",
    "print(f'Train score is {ogrid_lg.score(X_train,y_train)}')\n",
    "print(f'Test score is {ogrid_lg.score(X_test,y_test)}')\n",
    "\n",
    "\n",
    "# let's get the predictions\n",
    "X_test_preds = ogrid_lg.predict(X_testt)\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame({'Id': test.Id, 'Target':X_test_preds }).to_csv('solution_base1.csv', index =False)  \n",
    "print(\"Done :D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.868\n",
      "Best parameters: {'dtree__criterion': 'entropy', 'dtree__max_depth': 3, 'dtree__max_features': 'log2', 'dtree__splitter': 'best', 'smote__k_neighbors': 5}\n",
      "Train score is 0.9042553191489363\n",
      "Test score is 0.8928571428571429\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "pipe_roc_dtree = p([('smote',SMOTE()),('dtree',DecisionTreeClassifier(random_state=0))])\n",
    "param_roc_dtree = {'smote__k_neighbors': [2,3,5],\n",
    "                  'dtree__max_depth': [2,3,5],\n",
    "               'dtree__splitter':['random','best'],\n",
    "               'dtree__max_features':['auto','log2','sqrt'],\n",
    "               'dtree__criterion':['gini','entropy'],\n",
    "            }\n",
    "\n",
    "ogrid_dtree= GridSearchCV(pipe_roc_dtree,param_roc_dtree, cv=5, n_jobs=-1, scoring=ftwo_scorer)\n",
    "ogrid_dtree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Mean cross-validation score: {:.3f}\".format(ogrid_dtree.best_score_))\n",
    "print(\"Best parameters: {}\".format(ogrid_dtree.best_params_))\n",
    "print(f'Train score is {ogrid_dtree.score(X_train,y_train)}')\n",
    "print(f'Test score is {ogrid_dtree.score(X_test,y_test)}')\n",
    "\n",
    "# let's get the predictions\n",
    "X_test_preds = ogrid_dtree.predict(X_testt)\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame({'Id': test.Id, 'Target':X_test_preds }).to_csv('solution_base111.csv', index =False)  \n",
    "print(\"Done :D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.873\n",
      "Best parameters: {'knn__algorithm': 'kd_tree', 'knn__p': 3, 'knn__weights': 'uniform', 'smote__k_neighbors': 3}\n",
      "Train score is 0.9693877551020408\n",
      "Test score is 0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "#KNN \n",
    "\n",
    "pipe_roc_knn = p([('smote',SMOTE()),('knn',KNeighborsClassifier())])\n",
    "param_roc_knn = {'smote__k_neighbors': [2,3,5],\n",
    "                 'knn__weights':['uniform'],\n",
    "                 'knn__algorithm' :['kd_tree', 'brute'],\n",
    "                 'knn__p':[3]\n",
    "                }\n",
    "\n",
    "ogrid_knn= GridSearchCV(pipe_roc_knn,param_roc_knn, cv=5, n_jobs=-1, scoring=ftwo_scorer)\n",
    "ogrid_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Mean cross-validation score: {:.3f}\".format(ogrid_knn.best_score_))\n",
    "print(\"Best parameters: {}\".format(ogrid_knn.best_params_))\n",
    "print(f'Train score is {ogrid_knn.score(X_train,y_train)}')\n",
    "print(f'Test score is {ogrid_knn.score(X_test,y_test)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.874\n",
      "Best parameters: {'smote__k_neighbors': 2, 'svm__C': 0.1, 'svm__gamma': 'scale'}\n",
      "Train score is 0.913978494623656\n",
      "Test score is 1.0\n"
     ]
    }
   ],
   "source": [
    "#SVM rbf \n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "pipe_roc_svm = p([('smote',SMOTE()),('svm',svm.SVC(kernel='rbf'))])\n",
    "param_roc_svm = {'smote__k_neighbors': [2,3,5],\n",
    "                'svm__C':[0.001,0.01,0.1],\n",
    "                'svm__gamma':['scale','auto'],\n",
    "                }\n",
    "\n",
    "ogrid_svm_rbf= GridSearchCV(pipe_roc_svm,param_roc_svm, cv=5, n_jobs=-1, scoring=ftwo_scorer)\n",
    "ogrid_svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Mean cross-validation score: {:.3f}\".format(ogrid_svm_rbf.best_score_))\n",
    "print(\"Best parameters: {}\".format(ogrid_svm_rbf.best_params_))\n",
    "print(f'Train score is {ogrid_svm_rbf.score(X_train,y_train)}')\n",
    "print(f'Test score is {ogrid_svm_rbf.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.862\n",
      "Best parameters: {'rf__criterion': 'gini', 'rf__max_depth': 1, 'rf__max_features': 'log2', 'rf__min_samples_split': 2, 'rf__n_estimators': 150, 'smote__k_neighbors': 2}\n",
      "Train score is 0.8602150537634409\n",
      "Test score is 1.0\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pipe_roc_rf = p([('smote',SMOTE()),('rf',RandomForestClassifier(random_state=0))])\n",
    "param_roc_rf = {\n",
    "    \n",
    "                 'smote__k_neighbors': [2],\n",
    "                'rf__n_estimators' : [150],\n",
    "                 'rf__max_depth' : [1],\n",
    "                'rf__criterion' : [\"gini\",\"entropy\"],\n",
    "                'rf__min_samples_split' :[1,2],\n",
    "                'rf__max_features': [\"auto\",\"sqrt\",\"log2\"]\n",
    "                \n",
    "               }\n",
    "\n",
    "ogrid_rf= GridSearchCV(pipe_roc_rf,param_roc_rf, cv=7, n_jobs=-1, scoring=ftwo_scorer)\n",
    "ogrid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Mean cross-validation score: {:.3f}\".format(ogrid_rf.best_score_))\n",
    "print(\"Best parameters: {}\".format(ogrid_rf.best_params_))\n",
    "print(f'Train score is {ogrid_rf.score(X_train,y_train)}')\n",
    "print(f'Test score is {ogrid_rf.score(X_test,y_test)}')\n",
    "\n",
    "\n",
    "# let's get the predictions\n",
    "X_test_preds = ogrid_rf.predict(X_testt)\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame({'Id': test.Id, 'Target':X_test_preds }).to_csv('solution_base222.csv', index =False)  \n",
    "print(\"Done :D\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.841\n",
      "Best parameters: {'ee__n_estimators': 50, 'smote__k_neighbors': 1}\n",
      "Train score is 1.0\n",
      "Test score is 1.0\n"
     ]
    }
   ],
   "source": [
    "#easy ensemble classifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "pipe_roc_ee = p([('smote',SMOTE()),('ee',EasyEnsembleClassifier(random_state=0))])\n",
    "param_roc_ee = {'smote__k_neighbors': [1],\n",
    "                 'ee__n_estimators':[50]\n",
    "               }\n",
    "\n",
    "ogrid_ee= GridSearchCV(pipe_roc_ee,param_roc_ee, cv=5, n_jobs=-1, scoring=ftwo_scorer)\n",
    "ogrid_ee.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Mean cross-validation score: {:.3f}\".format(ogrid_ee.best_score_))\n",
    "print(\"Best parameters: {}\".format(ogrid_ee.best_params_))\n",
    "print(f'Train score is {ogrid_ee.score(X_train,y_train)}')\n",
    "print(f'Test score is {ogrid_ee.score(X_test,y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean cross-validation score: 0.821\n",
      "Best parameters: {'smote__k_neighbors': 3, 'xgb__learning_rate': 0.01, 'xgb__max_depth': 3}\n",
      "Train score is 0.9693877551020408\n",
      "Test score is 0.9259259259259259\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#XGBoost \n",
    "from  xgboost import XGBClassifier\n",
    "\n",
    "pipe_roc_xgb = p([('smote',SMOTE()),('xgb',XGBClassifier(random_state=0,\n",
    "                                                                            early_stopping_rounds=2,\n",
    "                                                                            n_estimators=150\n",
    "                                                                            \n",
    "                                                                             ))])\n",
    "param_roc_xgb = {\n",
    "                  'smote__k_neighbors': [1,2,3,5],\n",
    "                  'xgb__learning_rate' : [0.01],\n",
    "                  'xgb__max_depth' : [2,3,5]\n",
    "}\n",
    "\n",
    "ogrid_xgb= GridSearchCV(pipe_roc_xgb,param_roc_xgb, cv=5, n_jobs=-1, scoring=ftwo_scorer)\n",
    "ogrid_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Mean cross-validation score: {:.3f}\".format(ogrid_xgb.best_score_))\n",
    "print(\"Best parameters: {}\".format(ogrid_xgb.best_params_))\n",
    "\n",
    "print(f'Train score is {ogrid_xgb.score(X_train,y_train)}')\n",
    "print(f'Test score is {ogrid_xgb.score(X_test,y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross-validation score: 0.864\n",
      "parameters:  {'solver': 'adam', 'max_iter': 10000, 'alpha': 0.001, 'activation': 'logistic'}\n",
      "Train score:  0.913978494623656\n",
      "Test score:  1.0\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "#Neural Network(scikit learn MLPClassifier) with RandomizedSearchCV \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "nn = MLPClassifier(random_state=0)\n",
    "\n",
    "param_nn = {\n",
    "              'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "              'solver':['adam','lbfgs','sgd'],\n",
    "              'alpha':[0.001,0.01],\n",
    "              'max_iter':[10000],\n",
    "             # 'learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "            }\n",
    "\n",
    "\n",
    "#apply grid search\n",
    "grid_nn = RandomizedSearchCV(nn, param_nn, cv=5, n_jobs=-1, scoring=ftwo_scorer)\n",
    "grid_nn.fit(X_train, y_train)\n",
    "\n",
    "# Mean Cross Validation Score\n",
    "print(\"Best Mean Cross-validation score: {:.3f}\".format(grid_nn.best_score_))\n",
    "print('parameters: ', grid_nn.best_params_)\n",
    "print('Train score: ', grid_nn.score(X_train, y_train))\n",
    "print(\"Test score: \", grid_nn.score(X_test,y_test))\n",
    "\n",
    "\n",
    "# let's get the predictions\n",
    "X_test_preds = grid_nn.predict(X_testt)\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame({'Id': test.Id, 'Target':X_test_preds }).to_csv('solution_base5.csv', index =False)  \n",
    "print(\"Done :D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.6023391812865496\n",
      "Best param {'stack_method': 'auto'}\n",
      "Train score is 0.8695652173913043\n",
      "Test score is 1.0\n"
     ]
    }
   ],
   "source": [
    "#Stacking 1\n",
    "#Stacking of Data Sampling Algorithms(randomforest, xgboost,easyensemble) with logistic regression as my final estimator\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "sclf1 = StackingClassifier(estimators=\n",
    "                              [('randomforest', ogrid_rf.best_estimator_), \n",
    "                               ('xgboost', ogrid_xgb.best_estimator_), \n",
    "                               ('easyemsemble', ogrid_ee.best_estimator_),\n",
    "                              ],  final_estimator=LogisticRegression())\n",
    "sclf1_param = {\n",
    "                   'stack_method':['auto', 'predict_proba']\n",
    "                                   \n",
    "}\n",
    "sclf1_grid = GridSearchCV(sclf1, sclf1_param,cv=5, n_jobs=-1, scoring=ftwo_scorer)\n",
    "sclf1_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {sclf1_grid.best_score_}')\n",
    "print(f'Best param {sclf1_grid.best_params_}')\n",
    "print(f'Train score is {sclf1_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {sclf1_grid.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.906265664160401\n",
      "Best param {'dtree__max_depth': 1, 'logreg__C': 0.01, 'simplesvm__penalty': 'l1'}\n",
      "Train score is 0.9042553191489363\n",
      "Test score is 1.0\n"
     ]
    }
   ],
   "source": [
    "#Stacking 2\n",
    "#Stacking of cost sensitive algorithms(logistic reg, decision tree, simple svm) with xgboost as my final estimator\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "sclf2 = StackingClassifier(estimators=\n",
    "                              [('logreg', clogreg_grid.best_estimator_), \n",
    "                               ('dtree', cgrid_dtree.best_estimator_), \n",
    "                               ('simplesvm', cgrid_svc.best_estimator_),\n",
    "                              ],  final_estimator=XGBClassifier())\n",
    "sclf2_param = {\n",
    "               'logreg__C':[0.01],\n",
    "               'dtree__max_depth': [1,2,3],\n",
    "               'simplesvm__penalty':['l1','l2'],\n",
    "                           \n",
    "}\n",
    "sclf2_grid = GridSearchCV(sclf2, sclf2_param,cv=5, n_jobs=-1, scoring=ftwo_scorer)\n",
    "sclf2_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {sclf2_grid.best_score_}')\n",
    "print(f'Best param {sclf2_grid.best_params_}')\n",
    "print(f'Train score is {sclf2_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {sclf2_grid.score(X_test,y_test)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.8236842105263158\n",
      "Best param {'stack_method': 'predict_proba'}\n",
      "Train score is 0.9895833333333334\n",
      "Test score is 1.0\n"
     ]
    }
   ],
   "source": [
    "#Stacking 3\n",
    "#Stacking of basic Algorithms(knn, gradient boost and svm) with XGB as my final estimator\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "sclf3 = StackingClassifier(estimators=\n",
    "                              [('knn', grid_knn.best_estimator_), \n",
    "                               ('gbc', gbc_grid.best_estimator_), \n",
    "                               ('dtree', grid_dtree.best_estimator_),\n",
    "                              ],  final_estimator=XGBClassifier(random_state=42,early_stopping_rounds=2,objective= 'binary:logistic'))\n",
    "sclf3_param = {\n",
    "              #  'final_estimator__C' : [0.01,0.1],\n",
    "              #  'knn__n_neighbors': [2,3,5],\n",
    "              #  'gbc__learning_rate' : [0.01,0.1]\n",
    "                       'stack_method':['predict_proba']\n",
    "\n",
    "}\n",
    "sclf3_grid = GridSearchCV(sclf3, sclf3_param,cv=5, n_jobs=-1, scoring=ftwo_scorer)\n",
    "sclf3_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {sclf3_grid.best_score_}')\n",
    "print(f'Best param {sclf3_grid.best_params_}')\n",
    "print(f'Train score is {sclf3_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {sclf3_grid.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.8695652173913043\n"
     ]
    }
   ],
   "source": [
    "#Saving and uploading model using pickle for logistic regression model \n",
    "\n",
    "import pickle\n",
    "\n",
    "#logistic regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logreg=LogisticRegression(max_iter=1000)\n",
    "logreg_param= {\n",
    "    'C': [0.001,0.01,0.1,10,100],\n",
    "    'penalty':['l1', 'l2']\n",
    "}\n",
    "logreg_grid = GridSearchCV(logreg,logreg_param,cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "logreg_grid.fit(X_train,y_train)\n",
    "\n",
    "model = pickle.dumps(logreg_grid) \n",
    "model_from_pickle = pickle.loads(model) \n",
    "trainscore=model_from_pickle.score(X_train,y_train)\n",
    "\n",
    "testscore=model_from_pickle.score(X_test,y_test)\n",
    "print (f'train score {trainscore}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Mean Cross Validation Score is 0.8048767752715122\n",
      "Best param {'max_iter_predict': 150, 'n_restarts_optimizer': 2, 'warm_start': True}\n",
      "Train score is 1.0\n",
      "Test score is 0.9615384615384615\n"
     ]
    }
   ],
   "source": [
    "#GaussianProcessClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "gpc=GaussianProcessClassifier(random_state=0)\n",
    "\n",
    "gpc_param= { 'n_restarts_optimizer':[2,3,4],\n",
    "             'max_iter_predict':[150],\n",
    "              'warm_start':[True]  \n",
    "}\n",
    "#isoforest_grid = RandomizedSearchCV(isoforest, isoforest_param,cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "\n",
    "gpc_grid = GridSearchCV(gpc, gpc_param,cv=5,n_jobs=-1,scoring=ftwo_scorer)\n",
    "gpc_grid.fit(X_train,y_train)\n",
    "print(f'Best Mean Cross Validation Score is {gpc_grid.best_score_}')\n",
    "print(f'Best param {gpc_grid.best_params_}')\n",
    "print(f'Train score is {gpc_grid.score(X_train,y_train)}')\n",
    "print(f'Test score is {gpc_grid.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
